---

# See
# https://blogs.technet.microsoft.com/machinelearning/2015/05/20/choosing-a-learning-algorithm-in-azure-ml/
# 
# Terms
# predictor: independent variable
# target: dependent variable
# X: predictor dataframe
# Y: target variable dataframe
# class: a label of the labels of the categorical variable

- algorithm: template
  type: ~
  data_like: ~
  objective: ~
  concept: ~
  usage_note: ~
  code: |
    ~

- algorithm: lasso
  type: regression
  data_like:
  objective:
  concept:
  usage_note: Try using it before ridge regression
  code: |
    ~

- algorithm: linear regression
  task_type: supervised
  see: least squares linear regression
  sample: >
    Assumes sample has variables with Linear relationship, Multivariate
    normality, No or little multicollinearity, No auto-correlation,
    Homoscedasticity
    The coefficient of kurtosis (γ2) is the average of the fourth power of the standardized deviations from the mean. For a normal population, the coefficient of kurtosis is expected to equal 3. A value greater than 3 indicates a leptokurtic distribution; a values less than 3 indicates a platykurtic distribution.
  measures: >
    The correlation coefficient (ρ) is a measure that determines the degree to
    which two variables' movements are associated.
    Akaike information criterion (AIC) is an estimator of the relative quality of statistical models for a given set of data. the lower the better
    In statistics, the Bayesian information criterion (BIC) or Schwarz information criterion (also SIC, SBC, SBIC) is a criterion for model selection among a finite set of models; the model with the lowest BIC is preferred
    cost function, eg mean squared error, AKA L2 loss, 

- algorithm: least squares linear regression

- algorithm: polynomial regression
  sample_data: >
    visual inspection of the data shows a curvilinear relationship, is it appropriate to use a polynomial regression model

- algorithm: two-class logistic regression
  task_type: supervised
  model_type: regression
  data_description:
    sample_size: >50
    target_variable_type: binary category
  objective:
    explainable_boundaries: no
    task: classify
  concept: >
    Class is either 1 or 0. Cost (or loss?) function [?] bi-factor exponential [?].
    Metrics include accuracy, precision, recall (sensitivity), and F1 score. Accuracy is the
    percentage of outcomes that were predicted with correct class. Percision is the percentage
    of outcomes the classifier got correct out of the total number of prediction outcomes.
    WHat is the difference between percision and accuracy?
    Recall is the percentage of outcomes it predicted for a given class out of the total outcomes
    it should have predicted for that class. F1 is the harmonic mean of precision and recall.
    The receiver operating curve (ROC) is a graph used on classifiers that summarizes the performance
    of a classifier over all possible thresholds. It plots the true positive rate (y-axis) against
    the false positive rate as you vary the threshold for assigning observations to a class. In other words,
   it describes how much the model is capable of distinguishing between classes. Can fine-tune model with C-value.
  usage_note: ~
  prep: |
    # encode target if not already 1|0
    def encode_target(x):
        if x == 'label or value threshold': return(1)
        else: return(0)
    df['target']=df.target.apply(encode_target)
    # check means across all variables
    df.groupby('target').mean()
    # encode non-numerical predictor variables as 1|0
    predictor_1 = pd.get_dummies(df.predictor_1)
    predictor_2 = pd.get_dummies(df.predictor_2) # can encode multiple predictors
    predictor_1.columns = ['label_1a', 'label_1b']
    predictor_2.columns = ['label_2a', 'label_2b']
    # drop non-numerical columns that were encoded and original target variable
    X = df.drop(columns = ['predictor_1', 'predictor_2'])
    # concatenate encoded data and other numerical predictors
    X = pd.concat([X, predictor_1, predictor_2], axis = 1)
    # transform target to contiguous flattened (1-D) array
    Y = df.target
    Y = np.ravel(Y)
    # scale ?
  model: |
    from sklearn.linear_model import LogisticRegression
    from sklearn import metrics
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import classification_report
    from sklearn.metrics import confusion_matrix
    # fit model
    log_model = LogisticRegression()
    log_model.fit(X,Y)
    log_model.score(X,Y) # ?
    # get coefficients
    coeff_df = DataFrame(zip(X.columns, np.transpose(log_model.coef_)))
    # split data into training and teting sets
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y)
    log_model_training = LogisticRegression()
    log_model_training.fit(X_train,Y_train)
    # predict class
    class_predict = log_model_training.predict(X_test)
    # check prediction accuracy
    metrics.accuracy_score(Y_test, class_predict)
    classification_report(Y_test, class_predict)
    confusion_matrix(Y_test, class_predict) # y-axis is actual, x-axis is predicted, top left is origin
    

- algorithm: support vector machine
  model_type: regression
  task_type: supervised
  objective: [classify, time series analysis, regression analysis, anomaly detection, clustering analysis]
  concept: >
    Number of features should be less than number of samples.
    Hyperplane (2D or more) between two classes and (equally?) as far from the
    classes as possible (get maximum margin distance for less error rate).
    Could be linear or non-linear methods, by changing kernal (eg linear, RBF, etc)
    If possible.
    The support vectors are the planes made from class data points closest to the hyperplane.
    If classes have overlap and thus no hyperplane can cut through, try adding an additional dimension.
    Called kernal fit.
    Can use curving, rather than linear, using C and gamma parameters. 
    C [?], gamma [?] ... how close the edge of the vectors are [?]
  prep: |
    from sklearn.model_selection import train_test_split<Paste>
    from sklearn.utils import shuffle
    # encode target classes if not already integer [?]
    def encode_target(x):
        if x == 'label or value threshold': return(0)
        elif x == 'other label': return(1)
        else: return(2)
    Y=df.target.apply(encode_target)
    X=df.drop(columns=['target'])
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y)
    # scale data to be uniform
  model: |
    from sklearn.svm import SVC
    from sklearn.metrics import accuracy_score
    model = SVC() # alter kernal like: (kernal='linear')
    model.fit(X_train,Y_train)
    Y_predict = model.predict(X_test)
    accuracy_score(Y_test,Y_predict)
    # also try linear, gaussian radial basis function, and 3rd degree polynomial
    model_lin = svm.SVC(kernal='linear', C=C).fit(X_train,Y_train)
    model_rbf = svm.SVC(kernal='rbf', gamma=0.7, C=C).fit(X_train,Y_train)
    model_poly = svm.SVC(kernal='poly', degree=3, C=C).fit(X_train,Y_train)
    model_sig = svm.SVC(kernal='sigmoid' # [?] ).fit(X_train,Y_train)

- algorithm: naive bayes
  model_type: ~
  objective: classify
  concept: >
    Works well with large datasets. 
    Likelihood times prior over evidence = posterior
    Pros - multi-class prediction, good if assumption of independence holds,
    performs well with categorical variables.
    But if numerical, normal distribution is assumed.
    Cons - If variable added to test dataset and not in training, the variable
    is assigned 0 probability (eg, zero frequency). Laplace as a smoothing tech
    can help solve this issue.
  prep: |
    from sklearn.model_selection import train_test_split
    # Encode
    X = pd.get_dummies(df[['predictor_1', 'predictor_2']])
    Y = pd.DataFrame(df.target)
    X_train, X_test, Y_train, Y_test = train_test_split(X, Y)
    
  model: |
    from sklearn.naive_bayes import GaussianNB
    model = GaussianNB()
    model.fit(X_train, Y_train)
    # ...

- algorithm: Ensemble Machine Learning
  concept: |
    Multiple algorithms. Decrease variance (bagging w/ tree baggin, random forest, random subspace -- collecting weaker 'learners', aka bootstraping aggregation),
    voting for classification, averaging for regression
    Reduce bias
    (boosting w/ ada boost, XG boost, gradient boosting - fit weak learners that are slightly better than random to weighted versions of the data.
    also have parellel 
    ), and/or Improve predictions (stacking w/ stacking linear algos, stacking non-linear).

other:
  outliers: ~
  nans: |   
    import seaborn as sns
    df.info()
    sns.heatmap(df.isnull(), cbar=False)
  impute_values: ~
  fit: |
    cross-validation outputs [?]
  selection: cosnider bis, variance, error

genel: |
  pass y as 1-D array [?], chekc out ravel()
    
scale:
        concept: Scale features so that mean is ~0, scaling to unit variance. So that features' difference in scale does not affect. Scale before train-test split. (Not like below)
        code: |
scaler = StandardScaler()
X_scl = pd.DataFrame(data=scaler.fit_transform(X), columns=X.columns)
        X_trn_scl.round().describe()
        import seaborn as sb
        sb.distplot(X_trn_scl['sepal length (cm)'], kde=False)
sb.distplot(X_trn_scl['sepal width (cm)'], kde=False)
sb.distplot(X_trn_scl['petal length (cm)'], kde=False)
sb.distplot(X_trn_scl['petal width (cm)'], kde=False)

false_neg_pos
cm = pd.DataFrame(data=metrics.confusion_matrix(y_tst, predicted),
                  columns=iris.target_names, index=iris.target_names)

'''
           predicted 
             no  yes
  actual no  tn   fp
        yes  fn   tp

'''


classification report

sklearn.model_selection import cross_val_score


